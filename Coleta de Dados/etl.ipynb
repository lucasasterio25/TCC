{"cells":[{"cell_type":"markdown","source":["# Notebook Python TCC PUC Minas\n\nFluxo de execução -\nColeta dos dados para tabelas to tipo TMP -\nProcessamento das tabelas TMP com insercao para as tabelas DELTA e juncao dos datasets e criacao da tabela leads contendo todos os dados."],"metadata":{}},{"cell_type":"code","source":["#imports das bibliotecas usadas no codigo\nimport pandas as pd\nimport pyodbc\nfrom googleapiclient.discovery import build\nfrom oauth2client.service_account import ServiceAccountCredentials\nimport cryptography\nimport missingno as msno\nimport numpy as np"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["## celula de funcoes de coleta e tratamento dos dados\n#setupGA\nSCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\nDISCOVERY_URI = ('https://analyticsreporting.googleapis.com/$discovery/rest')\nCLIENT_SECRETS_PATH = {\n  \"type\": \"service_account\",\n  \"project_id\": \"XXX\",\n  \"private_key_id\": \"cfe7808e4f807fec3ccb0a0e820283ceaf9a8c62\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nTOKEN DE ACESSO=\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"XXX@XXX.iam.gserviceaccount.com\",\n  \"client_id\": \"XX\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/XX%40.iam.gserviceaccount.com\"\n}\nVIEW_ID = 'XXX'\n\n#cria variavel de conexao\ndef initialize_analyticsreporting(CLIENT_SECRETS_PATH):\n    credentials = ServiceAccountCredentials.from_json_keyfile_dict(CLIENT_SECRETS_PATH, SCOPES)\n    analytics = build('analyticsreporting', 'v4', credentials=credentials)\n    return analytics\n\n#pega dados do GA\ndef get_report_analytics(analytics):\n  return analytics.reports().batchGet(\n      body={\n        'reportRequests': [\n        {\n          'viewId': VIEW_ID,\n          'dateRanges': [{'startDate': '30daysAgo', 'endDate': 'today'}],\n          'metrics': [{'expression': 'ga:timeOnPage'}],\n          'dimensions': [{'name': 'ga:datehourminute'},\n                        {'name': 'ga:pagePath'},\n                        {'name': 'ga:campaign'},\n                        {'name': 'ga:campaignCode'},\n                        {'name': 'ga:dimension1'},\n                        {'name': 'ga:dimension2'}]\n        }]\n      }\n  ).execute()\n\ndef get_report_sql():\n  base_sql = spark.read.format(\"jdbc\") \\\n      .option(\"url\", f\"jdbc:sqlserver://XXX.database.windows.net:1433;databaseName={database}\") \\\n      .option(\"dbtable\", \"VENDAS\") \\\n      .option(\"user\", user) \\\n      .option(\"password\", password) \\\n      .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n      .load()\n  return base_sql\n\n#pega dados do ADS\ndef get_report_ads(analytics):\n  return analytics.reports().batchGet(\n      body={\n        'reportRequests': [\n        {\n          'viewId': VIEW_ID,\n          'dateRanges': [{'startDate': '30daysAgo', 'endDate': 'today'}],\n          'metrics':  [{'expression': 'ga:adClicks'},\n                        {'expression': 'ga:impressions'},\n                        {'expression': 'ga:visits'},\n                        {'expression': 'ga:cpc'},\n                        {'expression': 'ga:adcost'}],\n          'dimensions':[{'name': 'ga:campaign'},\n                        {'name': 'ga:data'}\n                        {'name': 'ga:campaignCode'},\n                        {'name': 'ga:keyword'}\n                       ]\n        }]\n      }\n  ).execute()\n\n# funcao de transformacao dos dados retornados do GA e ADS para dataframe\ndef response2df(response):\n  report = response.get('reports', [])[0] \n  # headers\n  header_dimensions = report.get('columnHeader', {}).get('dimensions', [])\n  header_metrics = [value['name'] for value in\n                    report.get('columnHeader', {}).get('metricHeader', {}).get('metricHeaderEntries', [])]\n  headers = header_dimensions + header_metrics\n  # removes \"ga:\" from each column\n  headers = list(map((lambda x: x.split(':', 1)[-1]), headers))\n  # values\n  values = []\n  rows = report.get('data', {}).get('rows', [])\n  for row in rows:\n      values_dimensions = row.get('dimensions', [])\n      values_metrics = row.get('metrics', [])[0].get('values', [])\n      values.append(values_dimensions + values_metrics)\n  # to dataframe\n  df = pd.DataFrame(columns=headers, data=values)\n  return df\n\n#tratamento de campos com defeitos no preenchimento\ndef clear_data_analytics(df):\n  df['datehourminute'].replace(np.nan, 'N/I', inplace=True)\n  df['pagePath'].replace(np.nan, 'N/I', inplace=True)\n  df['campaign'].replace(np.nan, 'N/I', inplace=True)\n  df['campaignCode'].replace(np.nan, 'N/I', inplace=True)\n  df['dimension1'].replace(np.nan, 'N/I', inplace=True)\n  df['dimension2'].replace(np.nan, 'N/I', inplace=True)\n  \n  df.dropna() \n  df.drop_duplicates(keep = False, inplace = True)\n  df[df['dimension2'] != np.nan]\n  return df\n\n#tratamento de campos com defeitos no preenchimento\ndef clear_data_ads(df):\n  df['datehourminute'].replace(np.nan, 'N/I', inplace=True)\n  df['pagePath'].replace(np.nan, 'N/I', inplace=True)\n  df['campaign'].replace(np.nan, 'N/I', inplace=True)\n  df['campaignCode'].replace(np.nan, 'N/I', inplace=True)\n  df['dimension1'].replace(np.nan, 'N/I', inplace=True)\n  df['dimension2'].replace(np.nan, 'N/I', inplace=True)\n  \n  df.dropna() \n  df.drop_duplicates(keep = False, inplace = True)\n  df[df['dimension2'] != np.nan]\n  \n  return df"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#camada de autenticacao\nanalytics = initialize_analyticsreporting(CLIENT_SECRETS_PATH)\n\n#camada de coleta\ndados_analytics = get_report_analytics(analytics)\ndados_ads = get_report_ads(analytics)\nbase_sql = get_report_sql()\n\n#camada de tratamento\nbase_analytics = response2df(dados_analytics)\nbase_ads = response2df(dados_ads)\n\n#camada de higienizacao\nbase_analytics = clear_data_analytics(base_analytics)\nbase_ads = clear_data_ads(base_ads)\n\n#camada de processamento\nbase_analytics = spark.createDataFrame(base_analytics)\nbase_analytics.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tmp_analytics\")\n\nbase_ads = spark.createDataFrame(base_ads)\nbase_ads.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tmp_ads\")\n\nbase_sql.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"tmp_vendas\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql \n-- inclusao dos dados novos \nINSERT INTO analytics\nSELECT * FROM tmp_analytics as a\nWHERE NOT EXISTS(SELECT 1 FROM analytics as b WHERE a.datehourminute = b.datehourminute);\n\n-- inclusao dos dados novos \nINSERT INTO analytics\nSELECT * FROM tmp_analytics as a\nWHERE datehourminute NOT IN (SELECT datehourminute FROM analytics);\n\n-- inclusao dos dados novos \nINSERT INTO vendas\nSELECT * FROM tmp_vendas as a\nWHERE CodigoIndicacao NOT IN (SELECT CodigoIndicacao FROM vendas);\n\n-- juncao e criacao da leads - tabela final do processo\nINSERT INTO leads\nSELECT Vendas.*, dimension1, TimeOnPage, Keyword, AdClicks, Impressions, CPC, AdCost, Visits, BounceRate\nFROM vendas\nLEFT JOIN analytics ON CodigoIndicacao =  analytics.CampaignID\nLEFT JOIN ads ON ads.CampaignID = analytics.CampaignID\nWHERE NOT EXISTS(SELECT 1 FROM leads as b WHERE vendas.cpf = b.cpf);\n"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"etl","notebookId":1565111926444708},"nbformat":4,"nbformat_minor":0}
